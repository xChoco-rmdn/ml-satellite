{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11836532,"sourceType":"datasetVersion","datasetId":7436431}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Satellite Image Preprocessing\n\nThis notebook handles all preprocessing steps for satellite imagery data including:\n- Data loading and validation\n- Image normalization\n- Data augmentation\n- Feature extraction\n- Data splitting","metadata":{"id":"CxFEjKXpR581"}},{"cell_type":"code","source":"# Remove directory and all its contents\nimport os\nos.system('rm -rf /kaggle/working/ml-satellite')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHgKo_CayXkp","outputId":"77eee543-c77c-4929-dbf8-6bd180128e97","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:04.033341Z","iopub.execute_input":"2025-05-17T01:10:04.033559Z","iopub.status.idle":"2025-05-17T01:10:04.044963Z","shell.execute_reply.started":"2025-05-17T01:10:04.033532Z","shell.execute_reply":"2025-05-17T01:10:04.044270Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import os\n\n# Current working directory\nprint(os.getcwd())\n\n# Clone the repository\n!git clone https://github.com/xChoco-rmdn/ml-satellite.git","metadata":{"id":"TPHub1rkSyPZ","outputId":"d789a682-515f-4bac-f4c7-f7074ad2374d","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:04.046472Z","iopub.execute_input":"2025-05-17T01:10:04.046897Z","iopub.status.idle":"2025-05-17T01:10:06.724222Z","shell.execute_reply.started":"2025-05-17T01:10:04.046872Z","shell.execute_reply":"2025-05-17T01:10:06.723418Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'ml-satellite'...\nremote: Enumerating objects: 231, done.\u001b[K\nremote: Counting objects: 100% (231/231), done.\u001b[K\nremote: Compressing objects: 100% (174/174), done.\u001b[K\nremote: Total 231 (delta 114), reused 140 (delta 51), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (231/231), 23.70 MiB | 31.94 MiB/s, done.\nResolving deltas: 100% (114/114), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"os.chdir('/kaggle/working/ml-satellite')\n\n# Install requirements\n!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:06.725234Z","iopub.execute_input":"2025-05-17T01:10:06.725557Z","iopub.status.idle":"2025-05-17T01:10:17.782401Z","shell.execute_reply.started":"2025-05-17T01:10:06.725521Z","shell.execute_reply":"2025-05-17T01:10:17.781557Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.18.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.7.2)\nRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.2.2)\nCollecting satpy>=0.30.0 (from -r requirements.txt (line 6))\n  Downloading satpy-0.56.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: xarray>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2025.1.2)\nRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\nRequirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.3.8)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.12.2)\nRequirement already satisfied: opencv-python>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (4.11.0.86)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.15.2)\nRequirement already satisfied: tensorboard>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.18.0)\nRequirement already satisfied: pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (11.1.0)\nRequirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (1.72.0rc1)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.37.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->-r requirements.txt (line 2)) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 4)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 4)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 4)) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 4)) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 4)) (3.0.9)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 5)) (3.6.0)\nRequirement already satisfied: dask>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (2024.12.1)\nCollecting donfig (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from satpy>=0.30.0->-r requirements.txt (line 6)) (4.3.8)\nRequirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from satpy>=0.30.0->-r requirements.txt (line 6)) (1.8.2)\nCollecting pykdtree (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading pykdtree-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\nCollecting pyorbital (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading pyorbital-1.10.1-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyproj>=2.2 in /usr/local/lib/python3.11/dist-packages (from satpy>=0.30.0->-r requirements.txt (line 6)) (3.7.1)\nCollecting pyresample>=1.24.0 (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading pyresample-1.34.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting trollimage>=1.24 (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading trollimage-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting trollsift (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading trollsift-0.5.3-py3-none-any.whl.metadata (780 bytes)\nCollecting zarr (from satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading zarr-3.0.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.0->-r requirements.txt (line 13)) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.0->-r requirements.txt (line 13)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.0->-r requirements.txt (line 13)) (3.1.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.45.1)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (8.1.8)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (2025.3.2)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (1.4.2)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (1.0.0)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (8.7.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.14.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=2.2->satpy>=0.30.0->-r requirements.txt (line 6)) (2025.4.26)\nCollecting configobj (from pyresample>=1.24.0->satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from pyresample>=1.24.0->satpy>=0.30.0->-r requirements.txt (line 6)) (2.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (2.4.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.0->-r requirements.txt (line 13)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->-r requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->-r requirements.txt (line 2)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->-r requirements.txt (line 2)) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->-r requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from pyorbital->satpy>=0.30.0->-r requirements.txt (line 6)) (0.7.1)\nCollecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr->satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading numcodecs-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->-r requirements.txt (line 2)) (2024.2.0)\nCollecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr->satpy>=0.30.0->-r requirements.txt (line 6))\n  Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nRequirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=0.17.1->dask[array]>=0.17.1->satpy>=0.30.0->-r requirements.txt (line 6)) (1.0.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.9.0->-r requirements.txt (line 1)) (0.1.2)\nDownloading satpy-0.56.0-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyresample-1.34.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pykdtree-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (398 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.3/398.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trollimage-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (658 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.4/658.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\nDownloading pyorbital-1.10.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trollsift-0.5.3-py3-none-any.whl (32 kB)\nDownloading zarr-3.0.7-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.9/203.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numcodecs-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\nDownloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: trollsift, donfig, crc32c, configobj, numcodecs, pykdtree, zarr, trollimage, pyresample, pyorbital, satpy\nSuccessfully installed configobj-5.0.9 crc32c-2.7.1 donfig-0.8.1.post1 numcodecs-0.16.0 pykdtree-1.4.1 pyorbital-1.10.1 pyresample-1.34.0 satpy-0.56.0 trollimage-1.26.0 trollsift-0.5.3 zarr-3.0.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htuUfcXszhp_","outputId":"21f64566-f14f-4c96-8b5c-0ce6ad582006","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.783473Z","iopub.execute_input":"2025-05-17T01:10:17.783769Z","iopub.status.idle":"2025-05-17T01:10:17.789322Z","shell.execute_reply.started":"2025-05-17T01:10:17.783734Z","shell.execute_reply":"2025-05-17T01:10:17.788547Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ml-satellite\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(os.listdir())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.790130Z","iopub.execute_input":"2025-05-17T01:10:17.790366Z","iopub.status.idle":"2025-05-17T01:10:17.815173Z","shell.execute_reply.started":"2025-05-17T01:10:17.790346Z","shell.execute_reply":"2025-05-17T01:10:17.814554Z"}},"outputs":[{"name":"stdout","text":"['.git', 'cloud_nowcasting_workflow.ipynb', 'artifacts', 'src', 'notebooks', 'run_workflow.py', 'setup.py', '.gitignore', 'requirements.txt', 'README.md', 'application.py']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"os.chdir('/kaggle/working/ml-satellite')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.815827Z","iopub.execute_input":"2025-05-17T01:10:17.816092Z","iopub.status.idle":"2025-05-17T01:10:17.831980Z","shell.execute_reply.started":"2025-05-17T01:10:17.816057Z","shell.execute_reply":"2025-05-17T01:10:17.831277Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime","metadata":{"id":"RjFz4lIfR582","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.834380Z","iopub.execute_input":"2025-05-17T01:10:17.834603Z","iopub.status.idle":"2025-05-17T01:10:17.849862Z","shell.execute_reply.started":"2025-05-17T01:10:17.834588Z","shell.execute_reply":"2025-05-17T01:10:17.849249Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Add the project root directory to Python path\nproject_root = str(Path(\"/kaggle/working/ml-satellite\").parent.parent)\nsys.path.append(project_root)","metadata":{"id":"zroXhD-eklc8","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.850735Z","iopub.execute_input":"2025-05-17T01:10:17.850987Z","iopub.status.idle":"2025-05-17T01:10:17.868375Z","shell.execute_reply.started":"2025-05-17T01:10:17.850954Z","shell.execute_reply":"2025-05-17T01:10:17.867726Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from src.components.data_ingestion import DataIngestion\nfrom src.components.data_transformations import DataTransformation\nfrom src.logger import logger\nfrom src.exception import CustomException","metadata":{"id":"HaPRbj0dkoSp","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:17.869171Z","iopub.execute_input":"2025-05-17T01:10:17.869413Z","iopub.status.idle":"2025-05-17T01:10:46.422623Z","shell.execute_reply.started":"2025-05-17T01:10:17.869396Z","shell.execute_reply":"2025-05-17T01:10:46.421850Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 01:10:29.436700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747444229.897615      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747444230.020577      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.423439Z","iopub.execute_input":"2025-05-17T01:10:46.424186Z","iopub.status.idle":"2025-05-17T01:10:46.428374Z","shell.execute_reply.started":"2025-05-17T01:10:46.424166Z","shell.execute_reply":"2025-05-17T01:10:46.427808Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ml-satellite\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 1. Data Loading and Exploration","metadata":{"id":"HjsPU2gvR583"}},{"cell_type":"code","source":"def setup_directories():\n    \"\"\"Create necessary directories if they don't exist\"\"\"\n    directories = [\n        'data/raw',\n        'data/processed',\n        'data/train',\n        'data/test',\n        'artifacts',\n        'logs'\n    ]\n    for directory in directories:\n        os.makedirs(directory, exist_ok=True)\n        print(f\"Created directory: {directory}\")","metadata":{"id":"xqQ0W7bqR583","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.429046Z","iopub.execute_input":"2025-05-17T01:10:46.429242Z","iopub.status.idle":"2025-05-17T01:10:46.548801Z","shell.execute_reply.started":"2025-05-17T01:10:46.429226Z","shell.execute_reply":"2025-05-17T01:10:46.548215Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def reshape_data_for_sequences_xy_nonoverlap(data, sequence_length=6):\n    \"\"\"Create X, y pairs for sequence prediction using non-overlapping windows.\"\"\"\n    n_samples = (len(data) - sequence_length) // sequence_length\n    X = np.zeros((n_samples, sequence_length, data.shape[1], data.shape[2], 1))\n    y = np.zeros((n_samples, sequence_length, data.shape[1], data.shape[2], 1))\n    for i in range(n_samples):\n        start = i * sequence_length\n        end = start + sequence_length\n        X[i] = data[start:end, :, :, np.newaxis]\n        y[i] = data[start+1:end+1, :, :, np.newaxis]\n    return X, y\n\ndef center_crop(data, target_height=256, target_width=256):\n    \"\"\"Crop the center of each frame in the data to the target size.\"\"\"\n    cropped = []\n    for frame in data:\n        h, w = frame.shape\n        start_h = (h - target_height) // 2\n        start_w = (w - target_width) // 2\n        cropped.append(frame[start_h:start_h+target_height, start_w:start_w+target_width])\n    return np.stack(cropped)","metadata":{"id":"69ORPaErleUt","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.549462Z","iopub.execute_input":"2025-05-17T01:10:46.549668Z","iopub.status.idle":"2025-05-17T01:10:46.569244Z","shell.execute_reply.started":"2025-05-17T01:10:46.549653Z","shell.execute_reply":"2025-05-17T01:10:46.568745Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 2. Data Preprocessing","metadata":{"id":"oRNgivFtR583"}},{"cell_type":"code","source":"setup_directories()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.569943Z","iopub.execute_input":"2025-05-17T01:10:46.570268Z","iopub.status.idle":"2025-05-17T01:10:46.594869Z","shell.execute_reply.started":"2025-05-17T01:10:46.570164Z","shell.execute_reply":"2025-05-17T01:10:46.594335Z"}},"outputs":[{"name":"stdout","text":"Created directory: data/raw\nCreated directory: data/processed\nCreated directory: data/train\nCreated directory: data/test\nCreated directory: artifacts\nCreated directory: logs\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Initialize components\ndata_ingestion = DataIngestion()\ndata_transformation = DataTransformation()\n\n# Get list of satellite files\nraw_data_path = os.path.join('/kaggle/input/himawari-ntb-202504/', 'Himawari_NTB_202504')\nsatellite_files = [os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if f.endswith('.nc')]\nif not satellite_files:\n    print(\"No satellite files found in data/raw directory\", sys)","metadata":{"id":"pI_2nMQtmAHe","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.595556Z","iopub.execute_input":"2025-05-17T01:10:46.595794Z","iopub.status.idle":"2025-05-17T01:10:46.966542Z","shell.execute_reply.started":"2025-05-17T01:10:46.595774Z","shell.execute_reply":"2025-05-17T01:10:46.965991Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uswS_gNjz19L","outputId":"48994701-3c39-4627-9716-9dfedf82df23","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.967164Z","iopub.execute_input":"2025-05-17T01:10:46.967409Z","iopub.status.idle":"2025-05-17T01:10:46.971341Z","shell.execute_reply.started":"2025-05-17T01:10:46.967391Z","shell.execute_reply":"2025-05-17T01:10:46.970439Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ml-satellite\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Process and ingest data\nprint(\"Starting data ingestion...\")\ningestion_result = data_ingestion.initiate_data_ingestion(satellite_files)\n\n# Load the processed data\ntrain_data = np.load(ingestion_result['train_file_path'])\ntest_data = np.load(ingestion_result['test_file_path'])\nprint(f\"Loaded training data shape: {train_data.shape}\")\nprint(f\"Loaded test data shape: {test_data.shape}\")\n\n# Clean and normalize data\nprint(\"Cleaning and normalizing data...\")\ntrain_data = data_transformation.clean_data(train_data)\ntest_data = data_transformation.clean_data(test_data)\n\ntrain_data = data_transformation.normalize_data(train_data)\ntest_data = data_transformation.normalize_data(test_data)\n\n# Crop data\nprint(\"Cropping data...\")\ntrain_data = center_crop(train_data, 256, 256)\ntest_data = center_crop(test_data, 256, 256)\n\n# Create sequences\nprint(\"Creating sequences...\")\nsequence_length = data_transformation.config.sequence_length\n\nX_train, y_train = reshape_data_for_sequences_xy_nonoverlap(train_data, sequence_length)\nX_test, y_test = reshape_data_for_sequences_xy_nonoverlap(test_data, sequence_length)\n\n# Save transformed data\nprint(\"Saving transformed data...\")\nnp.save('data/processed/X_train.npy', X_train)\nnp.save('data/processed/y_train.npy', y_train)\nnp.save('data/processed/X_test.npy', X_test)\nnp.save('data/processed/y_test.npy', y_test)\n\nprint(\"Preprocessing completed successfully!\")\nprint(f\"Transformed data shapes:\")\nprint(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\nprint(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n","metadata":{"id":"qg5H87HaR583","colab":{"base_uri":"https://localhost:8080/"},"outputId":"facef142-ba91-46c9-c032-2fa0bd9f1ab3","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:10:46.972093Z","iopub.execute_input":"2025-05-17T01:10:46.972388Z","iopub.status.idle":"2025-05-17T01:15:18.256684Z","shell.execute_reply.started":"2025-05-17T01:10:46.972359Z","shell.execute_reply":"2025-05-17T01:15:18.255707Z"}},"outputs":[{"name":"stderr","text":"Started data ingestion\n","output_type":"stream"},{"name":"stdout","text":"Starting data ingestion...\n","output_type":"stream"},{"name":"stderr","text":"Data ingestion completed. Files saved:\nProcessed files: 4199 files\nTrain data: data/train/train_data_20250401_0000_to_20250425_0100.npy\nTest data: data/test/test_data_20250425_0110_to_20250501_0000.npy\n","output_type":"stream"},{"name":"stdout","text":"Loaded training data shape: (3359, 271, 351)\nLoaded test data shape: (840, 271, 351)\nCleaning and normalizing data...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/ml-satellite/src/components/data_transformations.py:139: RuntimeWarning: invalid value encountered in cast\n  frame_uint8 = ((frame - frame.min()) * (255.0 / frame_range)).astype(np.uint8)\n","output_type":"stream"},{"name":"stdout","text":"Cropping data...\nCreating sequences...\nSaving transformed data...\nPreprocessing completed successfully!\nTransformed data shapes:\nX_train: (558, 6, 256, 256, 1), y_train: (558, 6, 256, 256, 1)\nX_test: (139, 6, 256, 256, 1), y_test: (139, 6, 256, 256, 1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Model Training ","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport tensorflow as tf\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n\nfrom src.pipeline.train_pipeline import TrainPipeline\nfrom src.logger import logger\nfrom src.exception import CustomException","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:15:18.257410Z","iopub.execute_input":"2025-05-17T01:15:18.257787Z","iopub.status.idle":"2025-05-17T01:15:18.262822Z","shell.execute_reply.started":"2025-05-17T01:15:18.257690Z","shell.execute_reply":"2025-05-17T01:15:18.262153Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def plot_training_history(history, save_path):\n    \"\"\"Plot and save training history\"\"\"\n    plt.figure(figsize=(12, 4))\n    \n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot metrics\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['mae'], label='Training MAE')\n    plt.plot(history.history['val_mae'], label='Validation MAE')\n    plt.title('Model MAE')\n    plt.xlabel('Epoch')\n    plt.ylabel('MAE')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:15:18.263439Z","iopub.execute_input":"2025-05-17T01:15:18.263701Z","iopub.status.idle":"2025-05-17T01:15:33.892865Z","shell.execute_reply.started":"2025-05-17T01:15:18.263681Z","shell.execute_reply":"2025-05-17T01:15:33.892194Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def main():\n    try:\n        logger.info(\"Starting training pipeline\")\n        os.makedirs('artifacts', exist_ok=True)\n        \n        # Initialize pipeline\n        trainer = TrainPipeline(batch_size=4)\n        \n        # Setup training strategy first\n        strategy = trainer.setup_training_strategy()\n        \n        # Load preprocessed data directly\n        logger.info(\"Loading preprocessed data from data/processed/ ...\")\n        X_train = np.load('data/processed/X_train.npy')\n        y_train = np.load('data/processed/y_train.npy')\n        X_test = np.load('data/processed/X_test.npy')\n        y_test = np.load('data/processed/y_test.npy')\n        logger.info(f\"Loaded X_train: {X_train.shape}, y_train: {y_train.shape}\")\n        logger.info(f\"Loaded X_test: {X_test.shape}, y_test: {y_test.shape}\")\n\n        # Create validation split from training data\n        val_split = 0.1\n        val_size = int(len(X_train) * val_split)\n        X_val = X_train[-val_size:]\n        y_val = y_train[-val_size:]\n        X_train = X_train[:-val_size]\n        y_train = y_train[:-val_size]\n        logger.info(f\"Split: X_train: {X_train.shape}, y_train: {y_train.shape}, X_val: {X_val.shape}, y_val: {y_val.shape}\")\n\n        # Build and compile model within strategy scope\n        with strategy.scope():\n            model = trainer.model_trainer.build_model()\n            model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n            \n        # Callbacks\n        callbacks = [\n            tf.keras.callbacks.ModelCheckpoint(\n                'artifacts/best_model.h5',\n                save_best_only=True,\n                monitor='val_loss'\n            ),\n            tf.keras.callbacks.EarlyStopping(\n                patience=10,\n                monitor='val_loss',\n                restore_best_weights=True\n            ),\n            tf.keras.callbacks.ReduceLROnPlateau(\n                factor=0.5,\n                patience=5,\n                monitor='val_loss',\n                min_lr=1e-6\n            ),\n            tf.keras.callbacks.TensorBoard(\n                log_dir='logs/fit',\n                histogram_freq=1,\n                update_freq='epoch',\n                profile_batch='100,120'\n            )\n        ]\n        \n        logger.info(\"Training model...\")\n        history = model.fit(\n            X_train, y_train,\n            validation_data=(X_val, y_val),\n            epochs=50,\n            batch_size=4,\n            callbacks=callbacks\n        )\n        \n        logger.info(\"Evaluating model on test set...\")\n        test_metrics = model.evaluate(X_test, y_test, verbose=1)\n        metrics = dict(zip(model.metrics_names, test_metrics))\n        logger.info(\"Test Set Metrics:\")\n        for metric_name, value in metrics.items():\n            logger.info(f\"{metric_name}: {value:.4f}\")\n            \n        logger.info(\"Saving final model...\")\n        model.save('artifacts/final_model.h5')\n        logger.info(\"Training pipeline completed successfully!\")\n        \n        plot_training_history(\n            history,\n            os.path.join('artifacts', f'training_history_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png')\n        )\n        return metrics, history\n        \n    except Exception as e:\n        logger.error(\"Error in training pipeline\")\n        raise CustomException(e, sys)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:15:33.893629Z","iopub.execute_input":"2025-05-17T01:15:33.893902Z","iopub.status.idle":"2025-05-17T01:15:33.913316Z","shell.execute_reply.started":"2025-05-17T01:15:33.893877Z","shell.execute_reply":"2025-05-17T01:15:33.912806Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Set memory growth for GPU if available\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        try:\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            logger.info(f\"Found {len(gpus)} GPU(s), memory growth enabled\")\n        except RuntimeError as e:\n            logger.warning(f\"Memory growth setting failed: {str(e)}\")\n    \n    main() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T01:15:33.913958Z","iopub.execute_input":"2025-05-17T01:15:33.914163Z","execution_failed":"2025-05-17T01:20:05.838Z"}},"outputs":[{"name":"stderr","text":"Found 2 GPU(s), memory growth enabled\nStarting training pipeline\nI0000 00:00:1747444536.907517      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1747444536.908160      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nUsing MirroredStrategy with 2 GPUs\nLoading preprocessed data from data/processed/ ...\nLoaded X_train: (558, 6, 256, 256, 1), y_train: (558, 6, 256, 256, 1)\nLoaded X_test: (139, 6, 256, 256, 1), y_test: (139, 6, 256, 256, 1)\nSplit: X_train: (503, 6, 256, 256, 1), y_train: (503, 6, 256, 256, 1), X_val: (55, 6, 256, 256, 1), y_val: (55, 6, 256, 256, 1)\nEnhanced 2D ConvLSTM Model built successfully\nInput shape: (6, 256, 256, 1)\nOutput shape: (None, 6, 256, 256, 1)\nTotal parameters: 1,699,749\nTraining model...\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1747444596.801364     126 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1747444596.801381     123 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: nan - mae: nan","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py:264: RuntimeWarning: invalid value encountered in less\n  if self.monitor_op(current, self.best):\n/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/reduce_lr_on_plateau.py:94: RuntimeWarning: invalid value encountered in less\n  self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m 16/126\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 1s/step - loss: nan - mae: nan","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}