
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This notebook handles model training using the project's pipeline system.\n",
    "It includes:\n",
    "- Loading preprocessed data\n",
    "- Model training with the training pipeline\n",
    "- Training visualization\n",
    "- Model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.pipeline.train_pipeline import TrainPipeline\n",
    "from src.logger import logger\n",
    "from src.exception import CustomException\n",
    "\n",
    "# Configure logging\n",
    "logger.info(\"Starting model training notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_preprocessed_data(data_dir='artifacts'):\n",
    "    \"\"\"\n",
    "    Load preprocessed training and testing data\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Directory containing preprocessed data files\n",
    "    \n",
    "    Returns:\n",
    "        tuple: X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X_train = np.load(os.path.join(data_dir, 'X_train.npy'))\n",
    "        y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "        X_test = np.load(os.path.join(data_dir, 'X_test.npy'))\n",
    "        y_test = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "        \n",
    "        logger.info(\"Preprocessed data loaded successfully\")\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load preprocessed data: {e}\")\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "# Load data\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data()\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def configure_gpu_memory():\n",
    "    \"\"\"\n",
    "    Configure GPU memory growth to prevent full memory allocation\n",
    "    \"\"\"\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Found {len(gpus)} GPU(s), memory growth enabled\")\n",
    "            logger.info(f\"GPU configuration completed: {len(gpus)} GPUs detected\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Memory growth setting failed: {str(e)}\")\n",
    "            logger.error(f\"GPU memory configuration failed: {e}\")\n",
    "\n",
    "def create_training_run_dir():\n",
    "    \"\"\"\n",
    "    Create a timestamped directory for this training run\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to training run directory\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    run_dir = os.path.join('artifacts', f'training_run_{timestamp}')\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "# Configure GPU\n",
    "configure_gpu_memory()\n",
    "\n",
    "# Create training run directory\n",
    "training_run_dir = create_training_run_dir()\n",
    "\n",
    "# Initialize training pipeline\n",
    "trainer = TrainPipeline(\n",
    "    batch_size=4,  # Adjust based on GPU memory\n",
    "    log_dir=training_run_dir\n",
    ")\n",
    "\n",
    "print(f\"Training run directory: {training_run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model(trainer, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train the model using the provided training pipeline\n",
    "    \n",
    "    Args:\n",
    "        trainer (TrainPipeline): Training pipeline instance\n",
    "        X_train, y_train: Training data\n",
    "        X_test, y_test: Test data\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Model metrics and training history\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting model training\")\n",
    "        \n",
    "        # Start training\n",
    "        metrics, history = trainer.initiate_training(\n",
    "            X_train, y_train, \n",
    "            X_test, y_test\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Model training completed successfully\")\n",
    "        return metrics, history\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model training failed: {e}\")\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "# Train the model\n",
    "metrics, history = train_model(trainer, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric_name, value in metrics.items():\n",
    "    print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_training_history(history, output_dir):\n",
    "    \"\"\"\n",
    "    Visualize training and validation metrics\n",
    "    \n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): Training history\n",
    "        output_dir (str): Directory to save plot\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        # MAE plot\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history.history['mae'], label='Training MAE')\n",
    "        plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "        plt.title('Mean Absolute Error')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        # RMSE plot\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history.history['rmse'], label='Training RMSE')\n",
    "        plt.plot(history.history['val_rmse'], label='Validation RMSE')\n",
    "        plt.title('Root Mean Square Error')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_dir, 'training_metrics_plot.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Training history plot saved to {plot_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to plot training history: {e}\")\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history, training_run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_calls": null,
   "metadata": {},
   "source": [
    "def save_training_results(metrics, history, output_dir):\n",
    "    \"\"\"\n",
    "    Save training metrics and history to CSV files\n",
    "    \n",
    "    Args:\n",
    "        metrics (dict): Model evaluation metrics\n",
    "        history (tf.keras.callbacks.History): Training history\n",
    "        output_dir (str): Directory to save results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Save training metrics\n",
    "        metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "        metrics_path = os.path.join(output_dir, 'training_metrics.csv')\n",
    "        metrics_df.to_csv(metrics_path, index=False)\n",
    "        \n",
    "        # Save training history\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_path = os.path.join(output_dir, 'training_history.csv')\n",
    "        history_df.to_csv(history_path, index=False)\n",
    "        \n",
    "        logger.info(f\"Training results saved in {output_dir}\")\n",
    "        print(f\"Training results saved in {output_dir}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save training results: {e}\")\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "# Save training results\n",
    "save_training_results(metrics, history, training_run_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
