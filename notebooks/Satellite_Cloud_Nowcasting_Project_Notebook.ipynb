{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecM9lWan13Yv"
      },
      "source": [
        "# Satellite Cloud Nowcasting Project: Himawari Imagery Analysis\n",
        "\n",
        "This notebook demonstrates the entire workflow for the Satellite Cloud Nowcasting project, which uses Himawari-8/9 satellite data for the NTB region.\n",
        "\n",
        "## Project Overview\n",
        "- **Domain**: Meteorological Nowcasting\n",
        "- **Focus**: Cloud Forecasting in Central Indonesia (NTB Region)\n",
        "- **Satellite**: Himawari-8/9 Band 13 (10.4 Âµm Infrared)\n",
        "- **Prediction Horizon**: 0-5 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urDa3Kf413Yw"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPIuq3aL13Yw"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Make sure the src module is in the path\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Import project modules\n",
        "from src.logger import logger\n",
        "from src.exception import CustomException\n",
        "from src.components.data_ingestion import DataIngestion\n",
        "from src.components.data_transformations import DataTransformation\n",
        "from src.components.model import CloudNowcastingModel\n",
        "from src.components.data_generator import SatelliteDataGenerator\n",
        "from src.components.model_evaluation import ModelEvaluator\n",
        "from src.pipeline.train_pipeline import TrainPipeline\n",
        "from src.pipeline.predict_pipeline import PredictionPipeline\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('artifacts', exist_ok=True)\n",
        "os.makedirs('data/processed/samples', exist_ok=True)\n",
        "os.makedirs('logs', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6RfIkd213Yx"
      },
      "source": [
        "## 2. Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftH6jHnn13Yx"
      },
      "outputs": [],
      "source": [
        "def check_sample_data():\n",
        "    \"\"\"\n",
        "    Check if sample data exists, if not, create synthetic data for testing\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"data/train\") or not os.path.exists(\"data/test\"):\n",
        "        logger.info(\"Sample data not found. Creating synthetic data for demonstration...\")\n",
        "\n",
        "        # Create directories\n",
        "        os.makedirs(\"data/train\", exist_ok=True)\n",
        "        os.makedirs(\"data/test\", exist_ok=True)\n",
        "\n",
        "        # Create synthetic satellite data\n",
        "        # 576 time steps (equivalent to 4 days at 10-min intervals)\n",
        "        # 400x400 spatial resolution\n",
        "\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Base pattern (cloud-like structures)\n",
        "        x = np.linspace(-10, 10, 400)\n",
        "        y = np.linspace(-10, 10, 400)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        base = np.exp(-(X**2 + Y**2) / 40)\n",
        "\n",
        "        # Create time-evolving synthetic data\n",
        "        train_data = np.zeros((576, 400, 400))\n",
        "        test_data = np.zeros((144, 400, 400))\n",
        "\n",
        "        # Generate training data with moving patterns\n",
        "        for t in range(576):\n",
        "            # Shift the pattern over time\n",
        "            shift_x = 5 * np.sin(t/100)\n",
        "            shift_y = 3 * np.cos(t/120)\n",
        "\n",
        "            # Create evolving pattern\n",
        "            pattern = np.roll(np.roll(base, int(shift_x), axis=0), int(shift_y), axis=1)\n",
        "\n",
        "            # Add some random noise\n",
        "            noise = 0.05 * np.random.randn(400, 400)\n",
        "\n",
        "            # Combine pattern and noise\n",
        "            train_data[t] = pattern + noise\n",
        "\n",
        "        # Generate test data continuing from training\n",
        "        for t in range(144):\n",
        "            # Shift the pattern over time (continuing from training)\n",
        "            shift_x = 5 * np.sin((t+576)/100)\n",
        "            shift_y = 3 * np.cos((t+576)/120)\n",
        "\n",
        "            # Create evolving pattern\n",
        "            pattern = np.roll(np.roll(base, int(shift_x), axis=0), int(shift_y), axis=1)\n",
        "\n",
        "            # Add some random noise\n",
        "            noise = 0.05 * np.random.randn(400, 400)\n",
        "\n",
        "            # Combine pattern and noise\n",
        "            test_data[t] = pattern + noise\n",
        "\n",
        "        # Scale to reasonable brightness temperature range (200-300K)\n",
        "        train_data = 250 + 50 * train_data\n",
        "        test_data = 250 + 50 * test_data\n",
        "\n",
        "        # Save the data\n",
        "        np.save(\"data/train/train_data_20250401_0000_to_20250425_0100.npy\", train_data)\n",
        "        np.save(\"data/test/test_data_20250425_0110_to_20250501_0000.npy\", test_data)\n",
        "\n",
        "        logger.info(\"Synthetic data created successfully\")\n",
        "        logger.info(f\"Training data shape: {train_data.shape}\")\n",
        "        logger.info(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "        return True\n",
        "    else:\n",
        "        # Check if the expected files exist\n",
        "        train_file = \"data/train/train_data_20250401_0000_to_20250425_0100.npy\"\n",
        "        test_file = \"data/test/test_data_20250425_0110_to_20250501_0000.npy\"\n",
        "\n",
        "        if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
        "            logger.info(\"Expected data files not found. Creating synthetic data...\")\n",
        "            # Remove existing directories and recreate synthetic data\n",
        "            os.system(\"rm -rf data/train data/test\")\n",
        "            return check_sample_data()\n",
        "\n",
        "        logger.info(\"Sample data found!\")\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKaZ4V2i13Yx"
      },
      "outputs": [],
      "source": [
        "# Check for sample data or create it\n",
        "check_sample_data()\n",
        "\n",
        "# Load the data\n",
        "train_data = np.load(\"data/train/train_data_20250401_0000_to_20250425_0100.npy\")\n",
        "test_data = np.load(\"data/test/test_data_20250425_0110_to_20250501_0000.npy\")\n",
        "\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RfJI4qP13Yx"
      },
      "source": [
        "### Visualize Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnOWrVfM13Yx"
      },
      "outputs": [],
      "source": [
        "# Visualize a few frames from the training data\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(train_data[i*10], cmap='jet', vmin=200, vmax=300)\n",
        "    plt.title(f'Frame {i*10}')\n",
        "    plt.colorbar(label='Brightness Temperature (K)')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Sample Frames from Training Data', y=1.05, fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKn6mrEu13Yx"
      },
      "source": [
        "## 3. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD5FOVFc13Yy"
      },
      "outputs": [],
      "source": [
        "# Initialize data transformation\n",
        "data_transform = DataTransformation()\n",
        "\n",
        "# Transform data\n",
        "logger.info(\"Starting data transformation...\")\n",
        "start_time = time.time()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = data_transform.initiate_data_transformation(\n",
        "    train_data, test_data\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "logger.info(f\"Data transformation completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Print the shapes\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyX1I0ci13Yy"
      },
      "source": [
        "### Visualize Sample Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcOoHGuA13Yy"
      },
      "outputs": [],
      "source": [
        "# Visualize a sample input and target sequence\n",
        "sample_idx = 0\n",
        "\n",
        "# Save sample sequences for future use\n",
        "np.save(\"data/processed/samples/sample_input_sequence.npy\", X_train[sample_idx])\n",
        "np.save(\"data/processed/samples/sample_target_sequence.npy\", y_train[sample_idx])\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Plot input sequence\n",
        "for i in range(X_train.shape[1]):  # For each time step in input sequence\n",
        "    plt.subplot(2, 6, i+1)\n",
        "    plt.imshow(X_train[sample_idx, i], cmap='jet')\n",
        "    plt.title(f'Input t-{X_train.shape[1]-i}')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "# Plot target sequence\n",
        "for i in range(y_train.shape[1]):  # For each time step in target sequence\n",
        "    plt.subplot(2, 6, i+7)\n",
        "    plt.imshow(y_train[sample_idx, i], cmap='jet')\n",
        "    plt.title(f'Target t+{i+1}')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Sample Input-Target Sequence Pair', y=1.05, fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmTNhwKo13Yy"
      },
      "source": [
        "## 4. Model Building and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkaooLFr13Yy"
      },
      "outputs": [],
      "source": [
        "# Add channel dimension to input and target sequences if needed\n",
        "if len(X_train.shape) == 3:\n",
        "    X_train = np.expand_dims(X_train, axis=-1)\n",
        "if len(y_train.shape) == 3:\n",
        "    y_train = np.expand_dims(y_train, axis=-1)\n",
        "if len(X_test.shape) == 3:\n",
        "    X_test = np.expand_dims(X_test, axis=-1)\n",
        "if len(y_test.shape) == 3:\n",
        "    y_test = np.expand_dims(y_test, axis=-1)\n",
        "\n",
        "# Check updated shapes\n",
        "print(f\"Updated X_train shape: {X_train.shape}\")\n",
        "print(f\"Updated y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzbrThUP13Yy"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model_builder = CloudNowcastingModel()\n",
        "\n",
        "# Set input shape based on the actual data dimensions\n",
        "model_builder.config.input_shape = X_train.shape[1:]\n",
        "model_builder.config.epochs = 10  # Reduced for demonstration\n",
        "\n",
        "# Build the model\n",
        "model = model_builder.build_model()\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osJmPh3A13Yy"
      },
      "outputs": [],
      "source": [
        "# Training with reduced epochs for demonstration\n",
        "logger.info(\"Starting model training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a validation split\n",
        "val_split = 0.1\n",
        "val_size = int(len(X_train) * val_split)\n",
        "\n",
        "X_val = X_train[-val_size:]\n",
        "y_val = y_train[-val_size:]\n",
        "X_train_final = X_train[:-val_size]\n",
        "y_train_final = y_train[:-val_size]\n",
        "\n",
        "# Train the model\n",
        "history = model_builder.train_model(\n",
        "    model,\n",
        "    train_data=(X_train_final, y_train_final),\n",
        "    valid_data=(X_val, y_val),\n",
        "    callbacks=[\n",
        "        # Save best model\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'artifacts/best_model.h5',\n",
        "            save_best_only=True,\n",
        "            monitor='val_loss'\n",
        "        ),\n",
        "        # Early stopping\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            patience=5,\n",
        "            monitor='val_loss',\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        # Reduce learning rate\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.5,\n",
        "            patience=2,\n",
        "            monitor='val_loss',\n",
        "            min_lr=1e-6\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "logger.info(f\"Model training completed in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Save the final model\n",
        "model.save('artifacts/final_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZLfcn9R13Yy"
      },
      "source": [
        "### Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s90qgOlz13Yy"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot MAE\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Training MAE')\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "plt.title('Model MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('artifacts/training_history.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do6rTNZg13Yy"
      },
      "source": [
        "## 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp1JBQ3413Yy"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "logger.info(\"Evaluating model on test set...\")\n",
        "test_metrics = model.evaluate(X_test, y_test, verbose=1)\n",
        "metrics = dict(zip(model.metrics_names, test_metrics))\n",
        "\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for metric_name, value in metrics.items():\n",
        "    print(f\"{metric_name}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNYLBjkg13Yy"
      },
      "outputs": [],
      "source": [
        "# Make predictions on a sample from the test set\n",
        "sample_idx = 5  # Select a random sample from test set\n",
        "sample_input = X_test[sample_idx:sample_idx+1]  # Add batch dimension\n",
        "\n",
        "# Make prediction\n",
        "sample_prediction = model.predict(sample_input)\n",
        "\n",
        "# Remove batch dimension\n",
        "sample_input = sample_input[0]\n",
        "sample_prediction = sample_prediction[0]\n",
        "sample_ground_truth = y_test[sample_idx]\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "# Plot the last frame of input sequence\n",
        "plt.subplot(3, 6, 1)\n",
        "plt.imshow(sample_input[-1, :, :, 0], cmap='jet')\n",
        "plt.title('Last Input Frame (t=0)')\n",
        "plt.colorbar()\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot ground truth and predictions side by side\n",
        "for i in range(sample_prediction.shape[0]):  # For each prediction time step\n",
        "    # Ground truth\n",
        "    plt.subplot(3, 6, i+7)\n",
        "    plt.imshow(sample_ground_truth[i, :, :, 0], cmap='jet')\n",
        "    plt.title(f'Ground Truth (t+{i+1})')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(3, 6, i+13)\n",
        "    plt.imshow(sample_prediction[i, :, :, 0], cmap='jet')\n",
        "    plt.title(f'Prediction (t+{i+1})')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('artifacts/prediction_sample.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5GZhI9q13Yz"
      },
      "source": [
        "## 6. Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTiwYGpG13Yz"
      },
      "outputs": [],
      "source": [
        "# Save data transformer for prediction pipeline\n",
        "from src.utils import save_object\n",
        "save_object('artifacts/data_transformer.pkl', data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYgnxpTv13Yz"
      },
      "outputs": [],
      "source": [
        "# Create a prediction pipeline using our latest time steps from test data\n",
        "try:\n",
        "    # Get a sample from test data\n",
        "    sample_input_sequence = X_test[0]  # First sequence in test data\n",
        "\n",
        "    # Initialize prediction pipeline\n",
        "    predictor = PredictionPipeline()\n",
        "\n",
        "    # Make prediction\n",
        "    logger.info(\"Making prediction using prediction pipeline...\")\n",
        "    prediction = predictor.predict(sample_input_sequence)\n",
        "\n",
        "    print(f\"Prediction shape: {prediction.shape}\")\n",
        "\n",
        "    # Visualize the prediction\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Plot the last input frame\n",
        "    plt.subplot(1, 7, 1)\n",
        "    plt.imshow(sample_input_sequence[-1, :, :, 0], cmap='jet')\n",
        "    plt.title('Last Input Frame (t=0)')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot the predicted frames\n",
        "    for i in range(prediction.shape[0]):\n",
        "        plt.subplot(1, 7, i+2)\n",
        "        plt.imshow(prediction[i], cmap='jet')\n",
        "        plt.title(f'Predicted (t+{i+1})')\n",
        "        plt.colorbar()\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('artifacts/pipeline_prediction.png')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in prediction pipeline: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR1Q2vrN13Yz"
      },
      "source": [
        "## 7. Running the Full Training Pipeline (Optional)\n",
        "\n",
        "This would start the full training pipeline using the `TrainPipeline` class, which includes optimized data generators, mixed precision training, and more advanced features. This might take longer to run, so it's optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhVtiw9O13Yz"
      },
      "outputs": [],
      "source": [
        "# Uncomment to run the full training pipeline\n",
        "'''\n",
        "# Initialize the training pipeline\n",
        "trainer = TrainPipeline(batch_size=4)  # Reduced batch size for memory efficiency\n",
        "\n",
        "# Start training\n",
        "logger.info(\"Starting full training pipeline...\")\n",
        "try:\n",
        "    metrics, history = trainer.initiate_training()\n",
        "    print(\"Training completed successfully!\")\n",
        "    print(\"\\nFinal Metrics:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in training pipeline: {str(e)}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9MDlhyN13Yz"
      },
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "This notebook has demonstrated the complete workflow for the Cloud Nowcasting project:\n",
        "\n",
        "1. **Data Ingestion**: Loading and preparing satellite data\n",
        "2. **Data Transformation**: Preprocessing, normalization, and sequence creation\n",
        "3. **Model Building**: Creating a ConvLSTM neural network architecture\n",
        "4. **Model Training**: Training the model with appropriate callbacks\n",
        "5. **Model Evaluation**: Assessing performance on test data\n",
        "6. **Prediction Pipeline**: Using the trained model for inference\n",
        "\n",
        "The trained model can be used for short-term cloud forecasting in the NTB region based on Himawari satellite imagery."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}